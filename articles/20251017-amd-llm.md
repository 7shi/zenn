---
title: "Ryzen AI Max+ 395 で LLM 推論速度を比較"
emoji: "🦙"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AMD", "Ryzen", "LLM", "AI"]
published: true
---

# はじめに

AMD Ryzen AI Max+ 395 を搭載した EVO-X2 で、gpt-oss:20b を CPU/GPU/NPU で動作させて処理速度を比較します。

:::message
本記事は Claude Code の生成結果をベースに編集しました。
:::

# 測定環境

- **プロセッサ**: AMD Ryzen AI Max+ 395（16コア）
- **モデル**: gpt-oss:20b
- **ソフトウェア**:
  - CPU/GPU: [Ollama](https://ollama.com/) 0.12.6
  - NPU: [FastFlowLM (FLM)](https://github.com/FastFlowLM/FastFlowLM) 0.9.13
- **プロンプト**: AIの将来を予測してください。
  - Ollama: `/set verbose` で測定
  - FLM: `/verbose` で測定

# 測定結果

単位: tokens/s（1秒あたりのトークン数）

| デバイス | プロンプト評価速度 | 生成速度 |
|---------|-----------------:|---------:|
| CPU     | 92.58            | 17.04    |
| GPU     | 401.46           | 44.58    |
| NPU     | 18.20            | 10.94    |

GPU が最も高速で、CPU は NPU よりも高い性能を示し、NPU は最も低速でした。

:::message
FLM では、プロンプト処理は Prefill、トークン生成は Decoding と表現されます。
:::

# NPU について

NPU には以下のような特徴があります。

- **CPU負荷の軽減**: NPU で推論を実行することで、CPU を他のタスクに使用できる
- **消費電力の効率**: NPU は AI 処理に特化しており、同じ処理を CPU で行うより消費電力が少ないとされている
- **モバイル用途での優位性**: バッテリー駆動のノート PC では、消費電力の低さが稼働時間に直結

Ryzen AI Max+ 395 は 16 コアという強力な CPU を搭載しているため、NPU の性能優位性が見られませんでした。

また、デスクトップ環境で LLM を動かす場合、以下の理由から NPU の優位性は限定的です。

- 十分な電力供給があるため、消費電力の差が大きな問題にならない
- 強力な GPU が利用可能
- CPU 負荷が掛からないのは GPU でも同様

ただし、複数の AI タスクを並行実行する場合や、AI タスクを実行しながら他の重い処理を行う場合には、NPU の存在意義が出てくる可能性があります。

これらの課題は業界でも認識されているようで、AMD が将来の Zen 6 系 APU 製品で NPU の搭載を取りやめる可能性があるという噂も出ています。

https://gazlog.com/entry/amd-zen6-no-more-npu/

# まとめ

Ryzen AI Max+ 395 での LLM 推論速度測定では、GPU > CPU > NPU という結果になりました。デスクトップ環境では、現時点では GPU での実行が推奨されます。

# 関連記事

NPU がなかなか活用されない状況について調査した記事です。NPU では大型モデルを動かすことは想定されておらず、処理速度もそれほど高速ではないことが示唆されました。

https://note.com/7shi/n/nb372abf33ba9
